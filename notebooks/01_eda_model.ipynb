{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffd7c5c",
   "metadata": {},
   "source": [
    "## Project Objective\n",
    "\n",
    "**Objective:**  \n",
    "Predict whether a student is **at risk of failing** based on academic, behavioral, and socio‑economic features from the UCI Student Performance dataset.\n",
    "\n",
    "**Use case:**  \n",
    "This project simulates an **early-warning system** used by universities or EdTech platforms to flag at‑risk students early, so teachers and mentors can intervene before the final exam.\n",
    "\n",
    "**Class balance:**  \n",
    "From the final grade \\(G3\\), about **67%** of students pass and **33%** fail, so the dataset is **moderately imbalanced** toward the pass class.\n",
    "\n",
    "***\n",
    "\n",
    "## Initial Data Observations\n",
    "\n",
    "1. The **`absences`** feature is highly skewed toward 0, meaning most students have very few absences and only a small group is frequently absent.  \n",
    "2. The **`failures`** feature shows that only a minority of students have multiple past failures.  \n",
    "3. Correlation analysis suggests that features like **`failures`**, **`age`**, and **`traveltime`** are **negatively correlated** with the final grade \\(G3\\), and can be associated with higher risk of failure, while higher **study time** tends to correlate with better performance.\n",
    "\n",
    "***\n",
    "\n",
    "## Step 1 – Data Quality Checks and Basic Cleaning\n",
    "\n",
    "- I checked for missing values across all columns.  \n",
    "- If any had appeared:\n",
    "  - **Numeric** features would be imputed with the median:  \n",
    "    `df[col].fillna(df[col].median(), inplace=True)`  \n",
    "  - **Categorical** features would be imputed with the mode:  \n",
    "    `df[col].fillna(df[col].mode()[0], inplace=True)`  \n",
    "- In this dataset, there are **no (or minimal) missing values**, so only basic checks were required, which simplifies preprocessing.\n",
    "\n",
    "***\n",
    "\n",
    "## Step 2 – Baseline Logistic Regression Model\n",
    "\n",
    "1. **Feature preprocessing**\n",
    "\n",
    "   - **Numeric features** are standardized with `StandardScaler` before logistic regression so that all features are on a comparable scale. This helps the optimizer and makes regularization behave meaningfully (e.g., age, absences, alcohol scores all on similar scales).  \n",
    "   - **Categorical features** are one‑hot encoded with `OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\")`.  \n",
    "     - `drop=\"first\"` avoids redundant dummy columns.  \n",
    "     - `handle_unknown=\"ignore\"` prevents errors when new categories appear in validation or test data.\n",
    "\n",
    "2. **Train–validation split**\n",
    "\n",
    "   - Data is split **80% / 20%** into training and validation sets.  \n",
    "   - I use **stratified splitting** to preserve the pass/fail proportion in both sets, which is important for imbalanced outcomes.\n",
    "\n",
    "3. **Regularization and pipeline**\n",
    "\n",
    "   - I use a **Logistic Regression** model with **L2 regularization**, which helps control overfitting, especially after one‑hot encoding many categorical variables.  \n",
    "   - A single **pipeline** combines:\n",
    "     - preprocessing (scaling + encoding)  \n",
    "     - the logistic regression model  \n",
    "   - This ensures the same transformations are consistently applied in training and validation.\n",
    "\n",
    "4. **Baseline scores**\n",
    "\n",
    "   - Training accuracy: **0.7436**  \n",
    "   - Validation accuracy: **0.7215**\n",
    "\n",
    "These are reasonable starting numbers, but accuracy alone is not enough for a risk‑sensitive early‑warning task.\n",
    "\n",
    "***\n",
    "\n",
    "## Step 3 – Evaluating the Baseline Logistic Regression\n",
    "\n",
    "1. **Why accuracy is not enough**\n",
    "\n",
    "   - Because only about one‑third of students fail, a model can achieve high accuracy by mostly predicting “pass”.  \n",
    "   - For an early‑warning system, the **cost of missing an at‑risk student (false negative)** is higher than the cost of flagging one extra student (false positive).\n",
    "\n",
    "2. **Baseline fail‑class metrics**\n",
    "\n",
    "   On the initial (unweighted, default threshold) model:\n",
    "\n",
    "   - Fail‑class **precision**: high  \n",
    "   - Fail‑class **recall**: low  \n",
    "   - Interpretation: the model is **too conservative**; when it predicts “at risk” it is often correct, but it **misses many failing students**.\n",
    "\n",
    "3. **ROC‑AUC**\n",
    "\n",
    "   - ROC‑AUC ≈ **0.77**, indicating reasonable ability to separate at‑risk vs not‑at‑risk students, but the default decision threshold prioritizes precision over recall.\n",
    "\n",
    "4. **Summary of baseline**\n",
    "\n",
    "   - On validation, the baseline logistic regression achieved about **0.62 precision** and **0.38 recall** for the fail class, with ROC‑AUC around **0.77**.  \n",
    "   - This makes it **unsafe as an early‑warning system without further tuning**, because too many at‑risk students are missed.\n",
    "\n",
    "***\n",
    "\n",
    "## Step 4 – Decision Tree + Regularization Experiments\n",
    "\n",
    "I then compared logistic regression with a decision tree and explored L1/L2 regularization and the regularization strength \\(C\\).\n",
    "\n",
    "### 4.1 Logistic Regression vs Decision Tree\n",
    "\n",
    "| Model                | Accuracy | Precision | Recall | F1    |\n",
    "|----------------------|----------|-----------|--------|-------|\n",
    "| Logistic Regression  | 0.721    | 0.625     | 0.384  | 0.476 |\n",
    "| Decision Tree        | 0.582    | 0.393     | 0.500  | 0.440 |\n",
    "\n",
    "- The **Decision Tree** achieves slightly **higher recall** but clearly lower accuracy and precision.  \n",
    "- The **Logistic Regression** is more stable overall but initially suffers from low recall.\n",
    "\n",
    "**Bias–variance view:**\n",
    "\n",
    "- The **Decision Tree** behaves like a **low‑bias, high‑variance** model: it can fit the training data closely but generalizes less consistently.  \n",
    "- The **Logistic Regression** behaves like a **higher‑bias, lower‑variance** model: it is more constrained, less likely to overfit, and usually more stable on validation.\n",
    "\n",
    "### 4.2 Regularization (L1, L2, and C)\n",
    "\n",
    "- I trained logistic regression with different **C values** (e.g. 0.1, 1.0, 10.0).  \n",
    "  - \\(C\\) is **inversely proportional** to regularization strength:\n",
    "    - **small C → strong regularization** (simpler, higher bias)  \n",
    "    - **large C → weak regularization** (more complex, higher variance)  \n",
    "- I also compared **L1** and **L2** penalties:\n",
    "  - **L1**:\n",
    "    - Encourages **sparse** solutions (some coefficients exactly zero).  \n",
    "    - Acts like implicit feature selection.  \n",
    "  - **L2**:\n",
    "    - Shrinks coefficients smoothly but rarely to zero.  \n",
    "    - Typically gives more stable generalization.\n",
    "\n",
    "**Observation:**\n",
    "\n",
    "- In my experiments, **L1** produced a **sparser model**, highlighting a smaller subset of strong predictors.  \n",
    "- **L2** produced a **more stable model** with slightly better generalization, so I kept L2 as the main production‑style model and used L1 mainly for interpretability and feature selection comparison.\n",
    "\n",
    "***\n",
    "\n",
    "## Step 5 – Model Interpretability and Feature Importance\n",
    "\n",
    "### 5.1 Logistic Regression Coefficients\n",
    "\n",
    "After preprocessing (scaling + one‑hot encoding), I inspected the logistic regression coefficients for the **fail class (at‑risk)**.\n",
    "\n",
    "**Top risk‑increasing features (positive coefficients):**\n",
    "\n",
    "- `failures` (coef ≈ 0.61)  \n",
    "- `schoolsup_yes` (extra school support) (coef ≈ 0.61)  \n",
    "- `goout` (coef ≈ 0.42)  \n",
    "- `Pstatus_T` (parents living together) (coef ≈ 0.39)  \n",
    "- `famsup_yes` (family support) (coef ≈ 0.38)  \n",
    "- `romantic_yes` (coef ≈ 0.28)  \n",
    "- `age` (coef ≈ 0.24)  \n",
    "- `nursery_yes` (attended nursery) (coef ≈ 0.22)  \n",
    "- `Dalc` (workday alcohol) (coef ≈ 0.19)  \n",
    "- `activities_yes` (coef ≈ 0.15)\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- The model assigns strong positive weights to **past failures** and **absences** (when included), indicating that students with more failures and higher absenteeism are much more likely to be classified as at‑risk.  \n",
    "- Some support-related variables (like `schoolsup_yes` or `famsup_yes`) can have positive coefficients because **support is often provided to weaker students**, so they correlate with existing risk rather than protection.\n",
    "\n",
    "**Top risk‑reducing features (negative coefficients):**\n",
    "\n",
    "- `traveltime` (slightly negative, coef ≈ −0.01)  \n",
    "- `school_MS` (coef ≈ −0.01)  \n",
    "- `studytime` (coef ≈ −0.09)  \n",
    "- `Walc` (weekend alcohol, coef ≈ −0.21)  \n",
    "- `internet_yes` (coef ≈ −0.22)  \n",
    "- `freetime` (coef ≈ −0.24)  \n",
    "- `famsize_LE3` (coef ≈ −0.24)  \n",
    "- `address_U` (urban, coef ≈ −0.26)  \n",
    "- `sex_M` (male, coef ≈ −0.30)  \n",
    "- `higher_yes` (wants higher education, coef ≈ −0.66)\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- Higher **study time** and aspiration for **higher education** strongly reduce predicted risk.  \n",
    "- Some lifestyle or context features (urban address, smaller family size, internet access) show negative coefficients, suggesting they are associated with relatively lower failure risk in this dataset.  \n",
    "- These signs and magnitudes must be interpreted carefully as **correlations**, not causal relationships.\n",
    "\n",
    "### 5.2 Decision Tree Feature Importance\n",
    "\n",
    "For the decision tree, the top features by importance were:\n",
    "\n",
    "- `absences` (importance ≈ 0.17)  \n",
    "- `failures` (≈ 0.13)  \n",
    "- `romantic_yes` (≈ 0.09)  \n",
    "- `goout` (≈ 0.08)  \n",
    "- `freetime` (≈ 0.08)  \n",
    "- `age` (≈ 0.05)  \n",
    "- `studytime` (≈ 0.05)  \n",
    "- `internet_yes` (≈ 0.05)  \n",
    "- `health` (≈ 0.05)  \n",
    "- `Walc` (≈ 0.05)\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "- The decision tree **also** highlights `absences`, `failures`, `studytime`, and behavior/lifestyle features (`goout`, `Walc`, `freetime`) as important splitting variables.  \n",
    "- This agreement between the tree and logistic regression strengthens the explanation that **attendance, prior failure history, and study/behavior patterns** are the key drivers of risk in this dataset.\n",
    "\n",
    "***\n",
    "\n",
    "## Step 6 – Improved Model (Class Weights & Threshold)\n",
    "\n",
    "To better align with the early‑warning use case, I improved the logistic regression by:\n",
    "\n",
    "1. Using **class weights** (e.g. `class_weight=\"balanced\"`) to give more importance to the minority fail class.  \n",
    "2. Tuning the **decision threshold** on predicted probabilities to trade some precision for higher recall.\n",
    "\n",
    "Final metrics (weighted logistic regression):\n",
    "\n",
    "- Validation accuracy ≈ **0.71**  \n",
    "- Fail‑class precision ≈ **0.55**  \n",
    "- Fail‑class recall ≈ **0.65**  \n",
    "- Fail‑class F1 ≈ **0.60**  \n",
    "- ROC‑AUC ≈ **0.76**\n",
    "\n",
    "This is a good trade‑off for an early‑warning system: the model catches a **larger share of at‑risk students**, accepting some extra false alarms so that fewer struggling students are missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Imports and data loading ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Load dataset\n",
    "data_path = \"../data/student-mat.csv\"\n",
    "df = pd.read_csv(data_path, sep=\";\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a35b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: Define target and feature sets ===\n",
    "\n",
    "# Binary target: 1 = at risk (fail), 0 = pass\n",
    "df[\"fail_target\"] = (df[\"G3\"] < 10).astype(int)\n",
    "target = \"fail_target\"\n",
    "\n",
    "# Numeric features (scaled)\n",
    "numeric_features = [\n",
    "    \"studytime\", \"failures\", \"absences\", \"age\", \"traveltime\",\n",
    "    \"freetime\", \"goout\", \"Dalc\", \"Walc\", \"health\"\n",
    "]\n",
    "\n",
    "# Categorical features (one-hot encoded)\n",
    "categorical_features = [\n",
    "    \"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\",\n",
    "    \"schoolsup\", \"famsup\", \"activities\", \"nursery\",\n",
    "    \"higher\", \"internet\", \"romantic\"\n",
    "]\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[target]\n",
    "\n",
    "print(\"Target balance (0=pass, 1=fail):\")\n",
    "display(y.value_counts(normalize=True).rename(\"proportion\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 3: Train–validation split (stratified) ===\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Train target distribution:\")\n",
    "display(y_train.value_counts(normalize=True).rename(\"proportion\"))\n",
    "print(\"Validation target distribution:\")\n",
    "display(y_val.value_counts(normalize=True).rename(\"proportion\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 4: Preprocessing pipeline (scaling + one-hot encoding) ===\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\"\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "beac3a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy (LogReg):      0.712\n",
      "Validation accuracy (LogReg): 0.709\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5: Logistic Regression with L2 + class_weight ===\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    solver=\"liblinear\",\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"  # focus on recall for minority (fail) class\n",
    ")\n",
    "\n",
    "log_reg_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", log_reg)\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_acc = log_reg_pipeline.score(X_train, y_train)\n",
    "val_acc = log_reg_pipeline.score(X_val, y_val)\n",
    "\n",
    "print(f\"Train accuracy (LogReg):      {train_acc:.3f}\")\n",
    "print(f\"Validation accuracy (LogReg): {val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec22cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Metrics for Logistic Regression ===\n",
    "\n",
    "# Predictions and probabilities\n",
    "y_val_pred_lr = log_reg_pipeline.predict(X_val)\n",
    "y_val_proba_lr = log_reg_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Scalar metrics\n",
    "acc_lr = accuracy_score(y_val, y_val_pred_lr)\n",
    "prec_lr = precision_score(y_val, y_val_pred_lr)\n",
    "rec_lr = recall_score(y_val, y_val_pred_lr)\n",
    "f1_lr = f1_score(y_val, y_val_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_val, y_val_proba_lr)\n",
    "\n",
    "print(\"Logistic Regression – Validation metrics\")\n",
    "print(f\"Accuracy : {acc_lr:.3f}\")\n",
    "print(f\"Precision: {prec_lr:.3f}\")\n",
    "print(f\"Recall   : {rec_lr:.3f}\")\n",
    "print(f\"F1-score : {f1_lr:.3f}\")\n",
    "print(f\"ROC-AUC  : {roc_auc_lr:.3f}\\n\")\n",
    "\n",
    "print(\"Classification report (LogReg):\")\n",
    "print(classification_report(y_val, y_val_pred_lr))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_lr = confusion_matrix(y_val, y_val_pred_lr)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm_lr, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_val, y_val_proba_lr)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"LogReg (AUC = {roc_auc_lr:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "plt.title(\"ROC Curve – Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d8b2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: c:\\Users\\BUNNY\\Projects\\student-risk-prediction-system\\models\\student_risk_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "import os, joblib\n",
    "\n",
    "save_path = \"../models/student_risk_pipeline.joblib\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "joblib.dump(log_reg_pipeline, save_path)\n",
    "print(\"Saved to:\", os.path.abspath(save_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: Decision Tree model and metrics ===\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(\n",
    "    max_depth=None,      # you can later tune: e.g., 3, 4, 5\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", dt_clf)\n",
    "    ]\n",
    ")\n",
    "\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred_dt = dt_pipeline.predict(X_val)\n",
    "y_val_proba_dt = dt_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "acc_dt = accuracy_score(y_val, y_val_pred_dt)\n",
    "prec_dt = precision_score(y_val, y_val_pred_dt)\n",
    "rec_dt = recall_score(y_val, y_val_pred_dt)\n",
    "f1_dt = f1_score(y_val, y_val_pred_dt)\n",
    "roc_auc_dt = roc_auc_score(y_val, y_val_proba_dt)\n",
    "\n",
    "print(\"Decision Tree – Validation metrics\")\n",
    "print(f\"Accuracy : {acc_dt:.3f}\")\n",
    "print(f\"Precision: {prec_dt:.3f}\")\n",
    "print(f\"Recall   : {rec_dt:.3f}\")\n",
    "print(f\"F1-score : {f1_dt:.3f}\")\n",
    "print(f\"ROC-AUC  : {roc_auc_dt:.3f}\\n\")\n",
    "\n",
    "print(\"Classification report (Decision Tree):\")\n",
    "print(classification_report(y_val, y_val_pred_dt))\n",
    "\n",
    "cm_dt = confusion_matrix(y_val, y_val_pred_dt)\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(cm_dt, annot=True, fmt=\"d\", cmap=\"Oranges\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix – Decision Tree\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e184d7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (fail)</th>\n",
       "      <th>Recall (fail)</th>\n",
       "      <th>F1 (fail)</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.708861</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.761974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.561321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision (fail)  Recall (fail)  F1 (fail)  \\\n",
       "0  Logistic Regression  0.708861          0.548387       0.653846   0.596491   \n",
       "1        Decision Tree  0.582278          0.393939       0.500000   0.440678   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.761974  \n",
       "1  0.561321  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Cell 8: Compare Logistic Regression vs Decision Tree ===\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Decision Tree\"],\n",
    "    \"Accuracy\": [acc_lr, acc_dt],\n",
    "    \"Precision (fail)\": [prec_lr, prec_dt],\n",
    "    \"Recall (fail)\": [rec_lr, rec_dt],\n",
    "    \"F1 (fail)\": [f1_lr, f1_dt],\n",
    "    \"ROC-AUC\": [roc_auc_lr, roc_auc_dt]\n",
    "})\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ff774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 9: Regularization experiments – L2 with different C and L1 ===\n",
    "\n",
    "def eval_log_reg_model(penalty=\"l2\", C_value=1.0, class_weight=\"balanced\"):\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        solver=\"liblinear\",\n",
    "        max_iter=1000,\n",
    "        C=C_value,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_val)\n",
    "    y_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    return {\n",
    "        \"penalty\": penalty,\n",
    "        \"C\": C_value,\n",
    "        \"acc\": accuracy_score(y_val, y_pred),\n",
    "        \"prec\": precision_score(y_val, y_pred),\n",
    "        \"rec\": recall_score(y_val, y_pred),\n",
    "        \"f1\": f1_score(y_val, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_val, y_proba)\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# L2 with different C\n",
    "for C_val in [0.1, 1.0, 10.0]:\n",
    "    results.append(eval_log_reg_model(penalty=\"l2\", C_value=C_val))\n",
    "\n",
    "# L1 with C=1.0\n",
    "results.append(eval_log_reg_model(penalty=\"l1\", C_value=1.0))\n",
    "\n",
    "reg_results = pd.DataFrame(results)\n",
    "reg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee541bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 10: Logistic Regression coefficients (feature importance) ===\n",
    "\n",
    "# Fit preprocessor alone to get feature names\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "num_feats = numeric_features\n",
    "cat_ohe = preprocessor.named_transformers_[\"cat\"].get_feature_names_out(categorical_features)\n",
    "all_features = np.concatenate([num_feats, cat_ohe])\n",
    "\n",
    "log_reg_model = log_reg_pipeline.named_steps[\"model\"]\n",
    "coefs = log_reg_model.coef_[0]\n",
    "\n",
    "feature_importance = (\n",
    "    pd.DataFrame({\"feature\": all_features, \"coef\": coefs})\n",
    "    .sort_values(by=\"coef\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Top positive coefficients (risk-increasing):\")\n",
    "display(feature_importance.head(10))\n",
    "\n",
    "print(\"Top negative coefficients (risk-reducing):\")\n",
    "display(feature_importance.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save trained pipeline ===\n",
    "import joblib  # usually installed with scikit-learn\n",
    "\n",
    "joblib.dump(log_reg_pipeline, \"../models/student_risk_pipeline.joblib\")\n",
    "print(\"Model pipeline saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
